{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "433dbb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator Pipeline from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/huixiann/tfgpu/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from math import log\n",
    "import textcleaner\n",
    "import string\n",
    "import emoji\n",
    "import re\n",
    "import pickle\n",
    "import collections\n",
    "import scipy\n",
    "import itertools\n",
    "import json\n",
    "import scipy.signal\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "username_cols = ['entropy', 'num_uppercase', 'num_lowercase', 'num_digits', 'num_punctuations', 'num_emojis', 'num_hashtags']\n",
    "username_model = joblib.load('../models_for_everyone/user_name.pkl')\n",
    "posts_model = joblib.load('../models_for_everyone/posts.pkl')\n",
    "\n",
    "news_model_filename = '../models_for_everyone/news_logregmodel.pkl'\n",
    "with open(news_model_filename, 'rb') as f:\n",
    "    news_model = pickle.load(f)\n",
    "    \n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb0165",
   "metadata": {},
   "source": [
    "## Predict Bot or Not through Username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33ad57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_known_expert(username):   \n",
    "    if username != None and username != '':\n",
    "        username = username.lower()        \n",
    "        if 'bot' in username:\n",
    "            #print('bot in username')\n",
    "            return 'bot'\n",
    "        else: \n",
    "            return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "def log2(number): \n",
    "    return log(number)/log(2)\n",
    "\n",
    "df_entropy = pd.read_csv('../models_for_everyone/names_dict.csv')\n",
    "df_entropy['log2'] = df_entropy['probability'].apply(log2)\n",
    "df_entropy_dict = df_entropy.set_index('character').to_dict()\n",
    "\n",
    "def get_entropy_of_text(text):\n",
    "    text = text.lower()\n",
    "    entropy = 0.0\n",
    "    if not text:\n",
    "        return -1\n",
    "\n",
    "    #text = remove_punctuations(text)\n",
    "    for char in text:\n",
    "        if char in df_entropy_dict['log2']:\n",
    "            entropy += df_entropy_dict['log2'][char]\n",
    "\n",
    "    return -entropy\n",
    "\n",
    "\n",
    "def get_num_uppercase_letters(text):\n",
    "    return sum(1 for c in text if c.isupper())\n",
    "\n",
    "def get_num_lowercase_letters(text):\n",
    "    return sum(1 for c in text if c.islower())\n",
    "\n",
    "def get_num_digits(text):\n",
    "    return sum(1 for c in text if c.isdigit())\n",
    "\n",
    "def get_num_punctuations(text):\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "    return count(text, set(string.punctuation))\n",
    "\n",
    "def get_num_hashtags(text):\n",
    "    return sum(1 for c in text if c=='#')\n",
    "\n",
    "def get_num_emojis(text):\n",
    "    return len(''.join(c for c in text if c in emoji.UNICODE_EMOJI['en']))\n",
    "\n",
    "def get_num_spaced_words(text):\n",
    "    return len(text.split(' '))\n",
    "\n",
    "def get_num_words(text):\n",
    "    return len(re.findall(r'\\w+', text))\n",
    "\n",
    "# col_name is user_name or screen_name\n",
    "def transform_df(df, col_name):\n",
    "    df['entropy'] = df[col_name].apply(get_entropy_of_text)\n",
    "    df['num_uppercase'] = df[col_name].apply(get_num_uppercase_letters)\n",
    "    df['num_lowercase'] = df[col_name].apply(get_num_lowercase_letters)\n",
    "    df['num_digits'] = df[col_name].apply(get_num_digits)\n",
    "    df['num_punctuations'] = df[col_name].apply(get_num_punctuations)\n",
    "    df['num_emojis'] = df[col_name].apply(get_num_emojis)\n",
    "    df['num_hashtags'] = df[col_name].apply(get_num_hashtags)\n",
    "    df['num_words'] = df[col_name].apply(get_num_spaced_words)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_username_prob(username):\n",
    "    if username == None or username == '':\n",
    "        return None\n",
    "    \n",
    "    username = username.lower()\n",
    "    \n",
    "    username_arr = [{'user_name': username}]\n",
    "    df = pd.DataFrame(username_arr)\n",
    "    df = transform_df(df, 'user_name')\n",
    "    df_test = df[username_cols]\n",
    "    predictions = username_model.predict_proba(df_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85eabab",
   "metadata": {},
   "source": [
    "## Bot Sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c54967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if text == '':\n",
    "        return ''\n",
    "    else:\n",
    "        text = text.lower()\n",
    "        text_cleaned = text.replace('rt', '')\n",
    "        text_cleaned = re.sub(r'@[A-Za-z0-9_]+', '', text_cleaned)\n",
    "        text_cleaned = re.sub(r'#[A-Za-z0-9_]+', '', text_cleaned)\n",
    "        text_cleaned = re.sub(r'https?:\\/\\/\\S*', '', text_cleaned)\n",
    "\n",
    "        output_list = text_cleaned.split(' ')\n",
    "        output = ' '.join([x for x in output_list if x != ''])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c50d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_self_declared_bot(data):\n",
    "    tweet_dict = data[0]\n",
    "    \n",
    "    screenname = tweet_dict['user']['screen_name']\n",
    "    username = tweet_dict['user']['name']\n",
    "    description = tweet_dict['user']['description']\n",
    "\n",
    "    if screenname is not None:\n",
    "        screenname = screenname.lower()\n",
    "        if 'bot' in screenname:\n",
    "            return True\n",
    "    elif username is not None:\n",
    "        username = username.lower()\n",
    "        if 'bot' in username:\n",
    "            return True\n",
    "    elif description is not None:\n",
    "        description = description.lower()\n",
    "        if 'bot' in description:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be7e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet_or_news(text):\n",
    "    preproc_text = preprocess_text(text)\n",
    "    text_arr = [preproc_text]\n",
    "    df_test = pd.DataFrame(text_arr, columns=['text'])\n",
    "    pred = news_model.predict(df_test)\n",
    "    return pred[0]\n",
    "\n",
    "def check_if_news_bot(data):\n",
    "    tweet_dict_1 = data[0]\n",
    "    screenname = tweet_dict_1['user']['screen_name']\n",
    "    description = tweet_dict_1['user']['description']\n",
    "    username = tweet_dict_1['user']['name']\n",
    "    \n",
    "    if screenname is not None:\n",
    "        screenname = screenname.lower()\n",
    "        if 'news' in screenname:\n",
    "            return True\n",
    "    if username is not None:\n",
    "        username = username.lower()\n",
    "        if 'news' in username:\n",
    "            return True\n",
    "    if description is not None:\n",
    "        description = description.lower()\n",
    "        if 'news' in description:\n",
    "            return True\n",
    "    \n",
    "    # for each tweet, check if it is news\n",
    "    news_or_not_arr = []\n",
    "    for tweet in data:       \n",
    "        try:\n",
    "            text = tweet['text']\n",
    "        except:\n",
    "            text = tweet['full_text']\n",
    "\n",
    "        if text == '':\n",
    "            news_or_not = 'tweet'\n",
    "        else:\n",
    "            processed_text = preprocess_text(text)\n",
    "            if processed_text == '':\n",
    "                news_or_not = 'tweet'\n",
    "            else:\n",
    "                news_or_not = predict_tweet_or_news(processed_text)\n",
    "\n",
    "        news_or_not_arr.append(news_or_not)\n",
    "\n",
    "    # if 80% are news, return news\n",
    "    arr_counter = collections.Counter(news_or_not_arr)\n",
    "    if (arr_counter['news'] / len(news_or_not_arr)) >= 0.80:\n",
    "        is_news_bot = True\n",
    "    else:\n",
    "        is_news_bot = False\n",
    "    \n",
    "    return is_news_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce26787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_bridging_bot(data):\n",
    "    num_more_than_2 = 0\n",
    "    \n",
    "    for tweet_dict in data:\n",
    "        try:\n",
    "            text = tweet_dict['text']\n",
    "        except:\n",
    "            text = tweet_dict['full_text']\n",
    "\n",
    "        if text == '':\n",
    "            return False\n",
    "        else:\n",
    "            sentence_split = text.split(' ')\n",
    "            num_mentions = 0\n",
    "            for w in sentence_split:\n",
    "                if w.startswith('@'):\n",
    "                    num_mentions += 1\n",
    "\n",
    "            if num_mentions >= 2:\n",
    "                num_more_than_2 += 1\n",
    "                \n",
    "            num_tweets = len(data)\n",
    "            if num_more_than_2 >= (num_tweets * 0.80):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3466bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_amplifier_bot(data):\n",
    "    amplifier_ref_mentions = 0\n",
    "    amplifier_ref_retweet = 0\n",
    "    \n",
    "    for tweet in data:\n",
    "        try:\n",
    "            text = tweet['text']\n",
    "        except:\n",
    "            text = tweet['full_text']\n",
    "\n",
    "        if text == '':\n",
    "            continue\n",
    "        else:\n",
    "            if text.startswith('RT'):\n",
    "                amplifier_ref_retweet += 1\n",
    "\n",
    "            sentence_split = text.split(' ')\n",
    "            for w in sentence_split:\n",
    "                if w.startswith('@'):\n",
    "                    amplifier_ref_mentions += 1\n",
    "                    break\n",
    "\n",
    "    perc_threshold = (len(data) * 0.80)\n",
    "\n",
    "    if amplifier_ref_retweet >= perc_threshold:\n",
    "        is_amplifier_bot = True\n",
    "        amplifier_type = 'retweet'\n",
    "\n",
    "    elif amplifier_ref_mentions >= perc_threshold:\n",
    "        is_amplifier_bot = True\n",
    "        amplifier_type = 'mentions'\n",
    "\n",
    "\n",
    "    elif (amplifier_ref_mentions + amplifier_ref_retweet) >= perc_threshold:\n",
    "        is_amplifier_bot = True\n",
    "        amplifier_type = 'retweet and mentions'\n",
    "\n",
    "    else:\n",
    "        is_amplifier_bot = False\n",
    "        amplifier_type = None\n",
    "                \n",
    "    return is_amplifier_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7c3b1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_prob(text):\n",
    "    #text_cleaned = preprocess_text(text)\n",
    "    #text_dict = [{'text_cleaned': text_cleaned}]\n",
    "    text_dict = [{'text_cleaned': text}]\n",
    "    df = pd.DataFrame(text_dict)\n",
    "    \n",
    "    post_text_prob = posts_model.predict_proba(df)\n",
    "    bot_prob = post_text_prob[0][0]\n",
    "    human_prob = post_text_prob[0][1]\n",
    "        \n",
    "    return bot_prob\n",
    "    \n",
    "def check_if_cyborg(data):\n",
    "    if len(data) <= 3:\n",
    "        return False\n",
    "    \n",
    "    initial_bot = None\n",
    "    initial_botscore = None\n",
    "    \n",
    "    num_flip = 0\n",
    "    change_in_score = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for tweet in data:\n",
    "        # run botbuster on text\n",
    "        try:\n",
    "            text = tweet['text']\n",
    "        except:\n",
    "            text = tweet['full_text']\n",
    "        \n",
    "        if text != '':                \n",
    "            botscore = get_posts_prob(text)\n",
    "            if botscore >= 0.5:\n",
    "                bot_or_not = True\n",
    "            else:\n",
    "                bot_or_not = False\n",
    "\n",
    "            if initial_bot == None:\n",
    "                initial_bot = bot_or_not\n",
    "                initial_botscore = botscore\n",
    "            else:\n",
    "                if bot_or_not != initial_bot:\n",
    "                    num_flip += 1\n",
    "\n",
    "                    initial_bot = bot_or_not\n",
    "\n",
    "                botscore_change = abs(initial_botscore - botscore)\n",
    "                change_in_score += botscore_change\n",
    "\n",
    "            count += 1\n",
    "    \n",
    "    #print(change_in_score, count)\n",
    "    avg_change_in_score = change_in_score / count\n",
    "    #print('num flips ', num_flip)\n",
    "    #print('avg score change ', avg_change_in_score)\n",
    "    \n",
    "    #if num_flip >= 3 and avg_change_in_score >= 0.10:\n",
    "    if num_flip >= 3 or change_in_score >= 0.02:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "432a77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_content_generation_bot(data):\n",
    "    is_retweet = 0\n",
    "\n",
    "    for tweet in data:\n",
    "        try:\n",
    "            text = tweet['text']\n",
    "        except:\n",
    "            text = tweet['full_text']\n",
    "\n",
    "        if text == '':\n",
    "            continue\n",
    "        else:\n",
    "            if text.startswith('RT'):\n",
    "                is_retweet += 1\n",
    "\n",
    "    if is_retweet >= (0.80 * len(data)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa87d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_periodicity(signal):    \n",
    "    if len(signal) <= 10:\n",
    "        return False, None\n",
    "        \n",
    "    try:\n",
    "        #df_signal = scipy.signal.find_peaks(signal)\n",
    "        #print('signal ', df_signal)\n",
    "\n",
    "        #if len(df_signal) <= 1:\n",
    "        #    return False, None\n",
    "\n",
    "        #df_signal = df_signal[0]\n",
    "        df_signal = signal\n",
    "        \n",
    "        diff_between_peaks = [x - df_signal[i - 1] for i, x in enumerate(df_signal)][1:]\n",
    "        #print('diff between peaks ', diff_between_peaks)\n",
    "        \n",
    "        if len(diff_between_peaks) == 1:\n",
    "            return True, diff_between_peaks[0]\n",
    "\n",
    "        b = collections.Counter(diff_between_peaks)\n",
    "\n",
    "        #most_common_key = b.most_common()[0][0]\n",
    "        most_common_val = b.most_common()[0][1]\n",
    "        \n",
    "        #print('most common val', most_common_val)\n",
    "\n",
    "        if most_common_val >= (0.5 * len(diff_between_peaks)):\n",
    "            return True, most_common_val\n",
    "        else:\n",
    "            return False, None\n",
    "    except:\n",
    "        return False, None\n",
    "\n",
    "def check_if_announcer_bot(data):\n",
    "    df_tweet_dict = pd.DataFrame.from_dict(data)\n",
    "    df_tweet_dict['created_at'] = pd.to_datetime(df_tweet_dict['created_at'])\n",
    "    df_time = df_tweet_dict['created_at'].dt.floor('H').value_counts().rename_axis('date').reset_index(name='count')\n",
    "    \n",
    "    df_time_arr = df_time['count'].tolist()\n",
    "    \n",
    "    periodicity, most_common_val = get_periodicity(df_time_arr)\n",
    "    \n",
    "    if periodicity == False:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1263272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_repeater_bot(data):\n",
    "    text_list = []\n",
    "\n",
    "    for tweet in data:\n",
    "        try:\n",
    "            text = tweet['text']\n",
    "        except:\n",
    "            text = tweet['full_text']\n",
    "\n",
    "        if text == '':\n",
    "            continue\n",
    "        else:\n",
    "            processed_text = preprocess_text(text)\n",
    "            if processed_text == '':\n",
    "                continue\n",
    "            else:\n",
    "                text_list.append(processed_text)\n",
    "                \n",
    "    num_pairs = 0\n",
    "    sim_arr = []\n",
    "\n",
    "    for pair in itertools.combinations(text_list, 2):\n",
    "        embedding_1 = model.encode(pair[0], convert_to_tensor=True)\n",
    "        embedding_2 = model.encode(pair[1], convert_to_tensor=True)\n",
    "\n",
    "        similarity = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "        sim_arr.append(similarity[0][0].item())\n",
    "\n",
    "        num_pairs += 1\n",
    "        \n",
    "    if np.array(sim_arr).mean() >= 0.50:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69a39d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e0a2b8b",
   "metadata": {},
   "source": [
    "## Now run it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1a457",
   "metadata": {},
   "source": [
    "Note: this is doing line by line. To do: make it aggregated user \n",
    "\n",
    "To redo:\n",
    "- Find number of lines in file \n",
    "- Read 1000 lines \n",
    "- Group by userid\n",
    "- Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "536c7cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_file = 'test.json'\n",
    "# out_datafile = 'test_bots.csv'\n",
    "\n",
    "# out_fh = open(out_datafile, 'w', encoding='utf-8')\n",
    "# out_fh.write('username,userid,botornot,self_declared_bot,news_bot,bridging_bot,amplifier_bot,cyborg,content_generation_bot,announcer_bot,repeater_bot\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "545b8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_bot(username, verified):\n",
    "    if verified == True:\n",
    "        bot_prob = 0\n",
    "        human_prob = 1\n",
    "        \n",
    "        return bot_prob, human_prob, False\n",
    "    \n",
    "    if check_known_expert(username) != 'bot':\n",
    "        pred = get_username_prob(username)\n",
    "        bot_prob = pred[0][0]\n",
    "        human_prob = pred[0][1]\n",
    "    else:\n",
    "        bot_prob = 1\n",
    "        human_prob = 0\n",
    "        \n",
    "    if bot_prob >= human_prob:\n",
    "        return bot_prob, human_prob, True\n",
    "    else:\n",
    "        return bot_prob, human_prob, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a45dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_type_of_bot(data, is_bot, out_fh):    \n",
    "#     for userid, data in bot_users.items():\n",
    "    username = data[0]['user']['screen_name']\n",
    "\n",
    "    self_declared_bot = check_if_self_declared_bot(data)\n",
    "\n",
    "    news_bot = check_if_news_bot(data)\n",
    "\n",
    "    bridging_bot = check_if_bridging_bot(data)\n",
    "\n",
    "    amplifier_bot = check_if_amplifier_bot(data)\n",
    "\n",
    "    cyborg = check_if_cyborg(data)\n",
    "\n",
    "    content_generation_bot = check_if_content_generation_bot(data)\n",
    "\n",
    "    announcer_bot = check_if_announcer_bot(data)\n",
    "\n",
    "    repeater_bot = check_if_repeater_bot(data)\n",
    "\n",
    "    num_posts = len(data)\n",
    "\n",
    "    out_fh.write(f'{username},{userid},{num_posts},{is_bot},{self_declared_bot},{news_bot},{bridging_bot},{amplifier_bot},{cyborg},{content_generation_bot},{announcer_bot},{repeater_bot}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a707a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you ran 0_splitfiles before this \n",
    "\n",
    "in_dir = './covid_2020_june_in_full_separated'\n",
    "out_dir = './covid_2020_june_out_full'\n",
    "\n",
    "file_list = os.listdir(in_dir)\n",
    "\n",
    "new_filename = os.path.join(out_dir, 'bot_sorter.csv')\n",
    "out_fh = open(new_filename, 'w', encoding='utf-8')\n",
    "out_fh.write('username,userid,num_posts,botornot,self_declared_bot,news_bot,bridging_bot,amplifier_bot,cyborg,content_generation_bot,announcer_bot,repeater_bot\\n')\n",
    "\n",
    "for file in file_list:    \n",
    "    if file.endswith('.json'):        \n",
    "        full_filename = os.path.join(in_dir, file)\n",
    "        \n",
    "        user_data = []\n",
    "        userid = None\n",
    "        verified = None\n",
    "        username = None\n",
    "        \n",
    "        with open(full_filename, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "\n",
    "                    if userid == None:\n",
    "                        userid = data['user']['id']\n",
    "                        verified = data['user']['verified']\n",
    "                        username = data['user']['screen_name']\n",
    "\n",
    "                    user_data.append(data)\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "        f.close()\n",
    "        \n",
    "        bot_prob, human_prob, is_bot = check_is_bot(username, verified)\n",
    "        check_type_of_bot(user_data, is_bot, out_fh)\n",
    "\n",
    "out_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081fb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab53647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For unsorted files \n",
    "\n",
    "in_dir = './covid_2020_june_in_full_separated'\n",
    "out_dir = './covid_2020_june_out_full'\n",
    "\n",
    "file_list = os.listdir(in_dir)\n",
    "\n",
    "new_filename = os.path.join(out_dir, 'bot_sorter.csv')\n",
    "out_fh = open(new_filename, 'w', encoding='utf-8')\n",
    "out_fh.write('username,userid,num_posts,botornot,self_declared_bot,news_bot,bridging_bot,amplifier_bot,cyborg,content_generation_bot,announcer_bot,repeater_bot\\n')\n",
    "\n",
    "for file in file_list:    \n",
    "    if file.endswith('.json'):        \n",
    "        full_filename = os.path.join(in_dir, file)\n",
    "        \n",
    "        bot_users = {}\n",
    "        non_bot_users = {}\n",
    "\n",
    "        with open(full_filename, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "\n",
    "                    userid = data['user']['id']\n",
    "                    verified = data['user']['verified']\n",
    "                    username = data['user']['screen_name']\n",
    "\n",
    "                    bot_prob, human_prob, is_bot = check_is_bot(username, verified)\n",
    "\n",
    "                    if is_bot:\n",
    "                        if userid not in bot_users:\n",
    "                            bot_users[userid] = []\n",
    "\n",
    "                        bot_users[userid].append(data)               \n",
    "\n",
    "                    else:\n",
    "                        if userid not in non_bot_users:\n",
    "                            non_bot_users[userid] = []\n",
    "\n",
    "                        non_bot_users[userid].append(data)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "check_type_of_bot(bot_users, True, out_fh)\n",
    "check_type_of_bot(bot_users, False, out_fh)\n",
    "\n",
    "out_fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb976b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
